---
title: 'Prediction Assignmet: Human activity recognition'
author: "Alessandro"
date: "10/30/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Overview

The goal of this project is to predict the manner in which some people did an exercise. 

## Data input and cleaning
The input data are downloded and loaded in the two data frame d_train and d_test
```{r eval=TRUE}
fileUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(fileUrl, destfile = "./training.csv", method = "curl")
d_train <- read.csv("training.csv")

fileUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(fileUrl, destfile = "./testing.csv", method = "curl")
d_test <- read.csv("testing.csv")
```
the training set appear to be full of missing data and many numeric column have been converted in factors because a division by zero made the character string #DIV/0! to be included.

```{r }
sum(is.na(d_train))
dim(d_train)
```

In order to take advantage of the maximum information I followed two strategies.
The training set is divided in two subsets

### First strategy (all possible consistent variables)

I consider a first subset called 'sub_train' that include all variables but without missing values for each observation line and I eliminate also possible constant columns and the strings #DIV/0! that will be converted in NA due to the conversion from factor to numeric of the column they belonged.
```{r warning=FALSE}
# Missing values elimination
sub_train <- d_train[complete.cases(d_train),]
# Eliminitaion of constant columns
sub_train <- sub_train[,(apply(sub_train, 2, function(x) !(length(unique(x)) == 1)))]
dim(sub_train)
# conversion from factor to numeric (they have been originally unintentionally  converted in factor by the presence of a character string)
for (i in 1:length(sub_train[1,])) {
    if ("#DIV/0!" %in% sub_train[,i]) {
        sub_train[,i] <- as.numeric(as.character(sub_train[,i]))
    }
}
# The missing value generated by the above conversion are still eliminated and again all possible constant columns
sub_train <- sub_train[complete.cases(sub_train),]
sub_train <- sub_train[,(apply(sub_train, 2, function(x) !(length(unique(x)) == 1)))]
dim(sub_train)
```
It's worth noting that now the data set dimension reduced a lot the observations from 19622 to 217 with a small reduction in the variable numbers from 160 to 150. A similar operation is performed on the d_test data set obtaining 'sub_test' data set.
```{r}
sub_test <- d_test[,names(sub_train[,1:149])]
# all NA are replaced with 0 
for (i in 1:length(sub_test[1,])) {
    if (NA %in% sub_test[,i]) {
        sub_test[,i] <- 0
    }
}
```

### Second Strategy (all possible observations)

A second sub data set has been obtained as the complement of the previous one. That is, the data set 'comp_train'. (see code and comments below)

```{r}
# comp_train represent all complementary information to sub_train  
comp_train <- d_train[!complete.cases(d_train),]
dim(comp_train)
# Now all the columns including (only) missing values or constant are eliminated
comp_train <- comp_train[,apply(comp_train, 2, function(x) !all(is.na(x)))]
comp_train <- comp_train[,apply(comp_train, 2, function(x) !all(x == ""))]
comp_train <- comp_train[,apply(comp_train, 2, function(x) !(length(unique(x)) == 1))]
dim(comp_train)
# This is the correspondent data set for test
comp_test <- d_test[,names(comp_train[,1:58])]
```
Now in this subset we have many observation (19216) but very few variables (59).
However they are now two clean data set and I processed both to select later the better strategy.

### Prediction (Bagging)

I tested many method but, for sake of simplicity, I reports only the best tradeoff in terms of accuracy and exceution time. I selected the Bagging method.\\
The cross validation is performed by the trainControl() function setting 10 folds with the default partition of p = 75%.
Both sub data sets 'comp_train' and 'sub_train' have been processed.
Observation (obs) and prediction (pred) from the cross validation process are available from the model with the field 'pred' (see below the code for 'predsubt').
This is based on the first strategy data set 'sub_train' (all possible variables)

```{r}
library(caret)
trCo <- trainControl(method = "cv",savePredictions = T,number = 10)
modsub3 <- train(classe ~ ., method = "treebag", data = sub_train,
                 trControl = trCo)
modsub3
predsubt <- modsub3$pred
confusionMatrix(predsubt$pred,predsubt$obs)
````
The accuracy level seems very good (0.9862) and, as we can see from the confusion matrix, only 3 cases are wrong over 217.
Let's see the behaviour related to the second strategy (all possible observations)
```{r}
modcomp3 <- train(classe ~ ., method = "treebag", data = comp_train,
                  trControl = trCo)
modcomp3
predcompt <- modcomp3$pred
confusionMatrix(predcompt$pred,predcompt$obs)
````
These results are at least  almost two order of magnitude better than the previous case! The accuracy is = 0.9998 and there are still 3 cases wrong but over 19216 observations. Finally in this case even if many information types have been removed, the big amount of observations seems to highly overcompensate this lack.

## Testing 

Finally the above two model have been used to predict the outcomes with the test data set properly adjusted for the two subset: 'sub_test' and 'comp_test'
As we can see from the prediction results both models agree on the fact that all exercises have been executed correctly (A outcome) in all 20 cases.

```{r}
print("Result prediction with treebag model based on data set sub_test")
predict(modsub3, sub_test)

print("Result prediction with treebag model based on data set comp_test")
predict(modcomp3,comp_test)

````


